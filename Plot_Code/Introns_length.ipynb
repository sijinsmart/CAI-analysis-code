{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8de0f6",
   "metadata": {},
   "source": [
    "### Introns data prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8890974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pysam\n",
    "from collections import defaultdict\n",
    "\n",
    "merged_file = \"data/RNA_Proteomics_Merged.csv\"\n",
    "gtf_file = \"/mnt/data_2/ensembl/Homo_sapiens.GRCh38.113.gtf\"\n",
    "fasta_file = \"/mnt/data_3/hallep/reference/hg38.fa\"\n",
    "out_fasta = \"data/introns_9056.fa\"\n",
    "out_csv   = \"data/introns_9056_metadata.csv\"\n",
    "\n",
    "merged_file = pd.read_csv(merged_file)\n",
    "merged_file[\"ENSG\"] = merged_file[\"Unnamed: 0\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "# load ENSG IDs from merged dataset\n",
    "ensg_ids = set(merged_file[\"ENSG\"].dropna())\n",
    "\n",
    "# parse GTF to collect exons by transcript \n",
    "exons_by_tx = defaultdict(list)\n",
    "\n",
    "with open(gtf_file) as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        chrom, source, feature, start, end, score, strand, frame, attrs = line.strip().split(\"\\t\")\n",
    "        if feature != \"exon\":\n",
    "            continue\n",
    "        # parse attributes\n",
    "        attr_dict = {kv.split(\" \")[0]: kv.split(\" \")[1].strip('\"') \n",
    "                     for kv in attrs.split(\";\") if kv.strip()}\n",
    "        gene_id = attr_dict.get(\"gene_id\")\n",
    "        transcript_id = attr_dict.get(\"transcript_id\")\n",
    "        if gene_id in ensg_ids:\n",
    "            exons_by_tx[(gene_id, transcript_id, chrom, strand)].append((int(start), int(end)))\n",
    "\n",
    "# Compute introns from exon coordinates\n",
    "introns = []\n",
    "for (gene_id, tx, chrom, strand), exons in exons_by_tx.items():\n",
    "    exons_sorted = sorted(exons, key=lambda x: x[0])\n",
    "    for i in range(len(exons_sorted)-1):\n",
    "        intron_start = exons_sorted[i][1] + 1\n",
    "        intron_end = exons_sorted[i+1][0] - 1\n",
    "        if intron_start < intron_end:\n",
    "            intron_num = i + 1  \n",
    "            introns.append((gene_id, tx, chrom, strand, intron_start, intron_end, intron_num))\n",
    "\n",
    "\n",
    "\n",
    "# Extract sequences from FASTA \n",
    "fasta = pysam.FastaFile(fasta_file)\n",
    "all_refs = set(fasta.references)\n",
    "\n",
    "def normalize_chrom(chrom):\n",
    "    \"\"\"Fix chromosome name mismatches between GTF and FASTA\"\"\"\n",
    "    if chrom in all_refs:\n",
    "        return chrom\n",
    "    if \"chr\" + chrom in all_refs:\n",
    "        return \"chr\" + chrom\n",
    "    if chrom.startswith(\"chr\") and chrom[3:] in all_refs:\n",
    "        return chrom[3:]\n",
    "    return None\n",
    "\n",
    "with open(out_fasta, \"w\") as out_fa, open(out_csv, \"w\") as out_tab:\n",
    "    out_tab.write(\"gene_id,transcript_id,intron_num,chrom,start,end,strand,length\\n\")\n",
    "    for gene_id, tx, chrom, strand, s, e, intron_num in introns:\n",
    "        chrom_name = normalize_chrom(chrom)\n",
    "        if chrom_name is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            seq = fasta.fetch(chrom_name, s-1, e).upper()  \n",
    "        except Exception as ex:\n",
    "            print(f\" Could not fetch {chrom_name}:{s}-{e} for {gene_id}: {ex}\")\n",
    "            continue\n",
    "\n",
    "        if strand == \"-\":  # reverse complement\n",
    "            seq = seq.translate(str.maketrans(\"ACGT\", \"TGCA\"))[::-1]\n",
    "\n",
    "        header = f\">{gene_id}|{tx}|intron{intron_num}|{chrom}:{s}-{e}({strand})\"\n",
    "        out_fa.write(f\"{header}\\n{seq}\\n\")\n",
    "\n",
    "        out_tab.write(f\"{gene_id},{tx},{intron_num},{chrom_name},{s},{e},{strand},{len(seq)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bdef51",
   "metadata": {},
   "source": [
    "### STEP1: Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a910111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length for codon97\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load intron metadata\n",
    "intron_df = pd.read_csv(\"data/introns_9056_metadata.csv\")\n",
    "\n",
    "# Collapse to per-gene total intron length\n",
    "intron_total = (\n",
    "    intron_df.groupby(\"gene_id\")[\"length\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"length\": \"total_intron_length\"})\n",
    ")\n",
    "\n",
    "# Load Codon97 dataset\n",
    "codon97_df = pd.read_csv(\"data/RNA_Proteomics_Filtered.csv\")\n",
    "\n",
    "# Merge on ENSG\n",
    "merged = codon97_df.merge(\n",
    "    intron_total, \n",
    "    left_on=\"ENSG_clean\", \n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Keep only gene name + total intron length\n",
    "result = merged[[\"GeneSymbol\", \"total_intron_length\"]]\n",
    "\n",
    "# Save for downstream analysis\n",
    "result.to_csv(\"data/codon97_intron.csv\", index=False)\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303baeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length for rna level\n",
    "rna_df = pd.read_csv(\"data/RNA_Proteomics_RNAlevel.csv\")\n",
    "\n",
    "rna_df[\"ENSG_clean\"] = rna_df[\"ESGN\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "rna_with_introns = rna_df.merge(\n",
    "    intron_total,\n",
    "    left_on=\"ENSG_clean\",   # make sure this matches your RNA file’s column name\n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "result = rna_with_introns[[\"GeneSymbol\", \"total_intron_length\"]]\n",
    "\n",
    "result.to_csv(\"data/rna_intron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbd63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length for proteomics\n",
    "prot_df = pd.read_csv(\"data/RNA_Proteomics_Proteinlevel.csv\")\n",
    "\n",
    "prot_df[\"ENSG_clean\"] = prot_df[\"ESGN\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "prot_with_introns = prot_df.merge(\n",
    "    intron_total,\n",
    "    left_on=\"ENSG_clean\",   # make sure this matches your Protein file’s column name\n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "result = prot_with_introns[[\"GeneSymbol\", \"total_intron_length\"]]\n",
    "\n",
    "result.to_csv(\"data/protein_intron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbe280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length for all_prot\n",
    "\n",
    "all_df = pd.read_csv(\"data/RNA_Proteomics_Merged.csv\")\n",
    "\n",
    "all_df[\"ENSG_clean\"] = all_df[\"Unnamed: 0\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "all_with_introns = all_df.merge(\n",
    "    intron_total,\n",
    "    left_on=\"ENSG_clean\",  \n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "all_gene_lengths = (\n",
    "    all_with_introns.groupby(\"GeneSymbol\")[\"total_intron_length\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "all_gene_lengths.to_csv(\"data/all_intron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f6611",
   "metadata": {},
   "source": [
    "#### bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def bootstrap_pvalue_mean(test_vals, all_vals, n_iter=1000, seed=123):\n",
    "    np.random.seed(seed)\n",
    "    test_mean = np.mean(test_vals)\n",
    "    n = len(test_vals)\n",
    "\n",
    "    boot_means = []\n",
    "    for _ in range(n_iter):\n",
    "        sample = np.random.choice(all_vals, size=n, replace=False)\n",
    "        boot_means.append(np.mean(sample))\n",
    "\n",
    "    boot_means = np.array(boot_means)\n",
    "    pval = np.mean(np.abs(boot_means - np.mean(all_vals)) >= \n",
    "                   np.abs(test_mean - np.mean(all_vals)))\n",
    "    return test_mean, np.mean(all_vals), pval\n",
    "\n",
    "\n",
    "def bootstrap_pvalue_median(test_vals, all_vals, n_iter=1000, seed=123):\n",
    "    np.random.seed(seed)\n",
    "    test_median = np.median(test_vals)\n",
    "    n = len(test_vals)\n",
    "\n",
    "    boot_medians = []\n",
    "    for _ in range(n_iter):\n",
    "        sample = np.random.choice(all_vals, size=n, replace=False)\n",
    "        boot_medians.append(np.median(sample))\n",
    "\n",
    "    boot_medians = np.array(boot_medians)\n",
    "    pval = np.mean(np.abs(boot_medians - np.median(all_vals)) >= \n",
    "                   np.abs(test_median - np.median(all_vals)))\n",
    "    return test_median, np.median(all_vals), pval\n",
    "\n",
    "codon97_df = pd.read_csv(\"/mnt/work_3/sijin/CAI/codon97_intron.csv\")\n",
    "rna_df     = pd.read_csv(\"/mnt/work_3/sijin/CAI/rna_intron.csv\")\n",
    "prot_df    = pd.read_csv(\"/mnt/work_3/sijin/CAI/protein_intron.csv\")\n",
    "all_df     = pd.read_csv(\"/mnt/work_3/sijin/CAI/all_intron.csv\")\n",
    "\n",
    "col = \"total_intron_length\"\n",
    "\n",
    "codon97_len = codon97_df[col].dropna().values\n",
    "rna_len     = rna_df[col].dropna().values\n",
    "prot_len    = prot_df[col].dropna().values\n",
    "all_len     = all_df[col].dropna().values  \n",
    "\n",
    "# mean\n",
    "results_mean = {}\n",
    "for label, values in {\n",
    "    \"Codon97\": codon97_len,\n",
    "    \"RNAseq\": rna_len,\n",
    "    \"Proteomics\": prot_len\n",
    "}.items():\n",
    "    results_mean[label] = bootstrap_pvalue_mean(values, all_len, n_iter=1000)\n",
    "\n",
    "res_df_mean = pd.DataFrame(results_mean, index=[\"Mean_Group\",\"Mean_AllProt\",\"p-value\"]).T\n",
    "print(\"=== Mean comparison (Total intron length per gene) ===\")\n",
    "print(res_df_mean)\n",
    "\n",
    "# median\n",
    "results_median = {}\n",
    "for label, values in {\n",
    "    \"Codon97\": codon97_len,\n",
    "    \"RNAseq\": rna_len,\n",
    "    \"Proteomics\": prot_len\n",
    "}.items():\n",
    "    results_median[label] = bootstrap_pvalue_median(values, all_len, n_iter=1000)\n",
    "\n",
    "res_df_median = pd.DataFrame(results_median, index=[\"Median_Group\",\"Median_AllProt\",\"p-value\"]).T\n",
    "print(\"\\n=== Median comparison (Total intron length per gene) ===\")\n",
    "print(res_df_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efe719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "codon97_df = pd.read_csv(\"/mnt/work_3/sijin/CAI/codon97_intron.csv\").rename(columns={\"total_intron_length\":\"Length\"})\n",
    "rna_df     = pd.read_csv(\"/mnt/work_3/sijin/CAI/rna_intron.csv\").rename(columns={\"total_intron_length\":\"Length\"})\n",
    "prot_df    = pd.read_csv(\"/mnt/work_3/sijin/CAI/protein_intron.csv\").rename(columns={\"total_intron_length\":\"Length\"})\n",
    "all_df     = pd.read_csv(\"/mnt/work_3/sijin/CAI/all_intron.csv\").rename(columns={\"total_intron_length\":\"Length\"})\n",
    "\n",
    "codon97_df[\"Source\"] = \"Codon97\"\n",
    "rna_df[\"Source\"]     = \"RNAseq_Log2FC>0\"\n",
    "prot_df[\"Source\"]    = \"Proteomics_Log2FC>0\"\n",
    "all_df[\"Source\"]     = \"All_otherprot_all_Log2FC\"\n",
    "\n",
    "\n",
    "all_data = pd.concat([codon97_df, rna_df, prot_df, all_df], ignore_index=True)\n",
    "\n",
    "all_data[\"Length\"] = pd.to_numeric(all_data[\"Length\"], errors=\"coerce\")\n",
    "\n",
    "all_data = all_data.dropna(subset=[\"Length\"])\n",
    "all_data = all_data[np.isfinite(all_data[\"Length\"])]\n",
    "\n",
    "all_data = all_data[all_data[\"Length\"] > 0].copy()\n",
    "\n",
    "order = [\"Codon97\", \"RNAseq_Log2FC>0\", \"Proteomics_Log2FC>0\", \"All_otherprot_all_Log2FC\"]\n",
    "counts = all_data.groupby(\"Source\").size()\n",
    "\n",
    "p_values = {\n",
    "    \"Codon97\": 0.079,\n",
    "    \"RNAseq_Log2FC>0\": 0.001,\n",
    "    \"Proteomics_Log2FC>0\": 0.824\n",
    "}\n",
    "\n",
    "custom_palette = {\n",
    "    \"Codon97\": \"#8DD3C7\",\n",
    "    \"RNAseq_Log2FC>0\": \"#c2bed6\",\n",
    "    \"Proteomics_Log2FC>0\": \"#f6f6bc\",\n",
    "    \"All_otherprot_all_Log2FC\": \"#eab375\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.violinplot(\n",
    "    x=\"Source\", y=\"Length\", data=all_data,\n",
    "    order=order, palette=custom_palette,\n",
    "    inner=None, linewidth=1.2,\n",
    "    log_scale=True  \n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"Source\", y=\"Length\", data=all_data,\n",
    "    order=order, color=\"black\",\n",
    "    alpha=0.2, jitter=0.25, size=1.5\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"Source\", y=\"Length\", data=all_data,\n",
    "    order=order, width=0.15, showcaps=True,\n",
    "    boxprops={\"facecolor\": \"grey\", \"edgecolor\": \"black\"},\n",
    "    whiskerprops={\"color\": \"black\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1},\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "group_means = all_data.groupby(\"Source\")[\"Length\"].mean()\n",
    "for i, src in enumerate(order):\n",
    "    ax.scatter(i, group_means[src], color=\"white\", zorder=3, s=30, edgecolors=\"black\")\n",
    "    ax.text(i, group_means[src] * 1.05, f\"mean = {group_means[src]:.0f}\",\n",
    "            ha=\"center\", va=\"bottom\", fontsize=10, color=\"blue\")\n",
    "\n",
    "# Add p-value lines vs Allprot\n",
    "y_max = all_data[\"Length\"].max()\n",
    "base = math.log10(y_max)\n",
    "log_step = 0.4  \n",
    "\n",
    "for i, src in enumerate(order[:-1]):  \n",
    "    x1, x2 = i, len(order)-1\n",
    "    pval = p_values.get(src, None)\n",
    "    if pval is None:\n",
    "        continue\n",
    "    \n",
    "    y = 10**(base + (i+1)*log_step)\n",
    "    line_height = 10**(base + (i+1)*log_step + 0.1)\n",
    "    \n",
    "    plt.plot([x1, x1, x2, x2], [y, line_height, line_height, y],\n",
    "             lw=1.2, c='k')\n",
    "    plt.text((x1+x2)/2, line_height*1.1, f\"p = {pval:.3f}\",\n",
    "             ha='center', va='bottom', fontsize=10, color=\"blue\")\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=range(len(order)),\n",
    "    labels=[f\"{src}\\n(n={counts.get(src, 0)})\" for src in order]\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of Total Intron Length (log scale)\", fontsize=14)\n",
    "plt.ylabel(\"Total Intron Length\", fontsize=12)\n",
    "plt.xlabel(\"\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "ax.set_ylim(1e1,1e8)\n",
    "\n",
    "plt.tight_layout()\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "\n",
    "mpl.rcParams[\"svg.fonttype\"] = \"none\"\n",
    "outdir = Path(\"/mnt/work_3/sijin/CAI/figs\")\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(outdir / \"Revised_Intron_Length_Dist.svg\",\n",
    "            format=\"svg\", bbox_inches=\"tight\", facecolor=\"white\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
