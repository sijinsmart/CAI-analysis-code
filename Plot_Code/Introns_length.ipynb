{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8de0f6",
   "metadata": {},
   "source": [
    "### Introns data prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8890974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pysam\n",
    "from collections import defaultdict\n",
    "\n",
    "merged_file = \"data/RNA_Proteomics_Merged.csv\"\n",
    "gtf_file = \"/mnt/data_2/ensembl/Homo_sapiens.GRCh38.113.gtf\"\n",
    "fasta_file = \"/mnt/data_3/hallep/reference/hg38.fa\"\n",
    "out_fasta = \"data/introns_9056.fa\"\n",
    "out_csv   = \"data/introns_9056_metadata.csv\"\n",
    "\n",
    "merged_file = pd.read_csv(merged_file)\n",
    "merged_file[\"ENSG\"] = merged_file[\"Unnamed: 0\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "# load ENSG IDs from merged dataset\n",
    "ensg_ids = set(merged_file[\"ENSG\"].dropna())\n",
    "\n",
    "# parse GTF to collect exons by transcript \n",
    "exons_by_tx = defaultdict(list)\n",
    "\n",
    "with open(gtf_file) as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        chrom, source, feature, start, end, score, strand, frame, attrs = line.strip().split(\"\\t\")\n",
    "        if feature != \"exon\":\n",
    "            continue\n",
    "        # parse attributes\n",
    "        attr_dict = {kv.split(\" \")[0]: kv.split(\" \")[1].strip('\"') \n",
    "                     for kv in attrs.split(\";\") if kv.strip()}\n",
    "        gene_id = attr_dict.get(\"gene_id\")\n",
    "        transcript_id = attr_dict.get(\"transcript_id\")\n",
    "        if gene_id in ensg_ids:\n",
    "            exons_by_tx[(gene_id, transcript_id, chrom, strand)].append((int(start), int(end)))\n",
    "\n",
    "# Compute introns from exon coordinates\n",
    "introns = []\n",
    "for (gene_id, tx, chrom, strand), exons in exons_by_tx.items():\n",
    "    exons_sorted = sorted(exons, key=lambda x: x[0])\n",
    "    for i in range(len(exons_sorted)-1):\n",
    "        intron_start = exons_sorted[i][1] + 1\n",
    "        intron_end = exons_sorted[i+1][0] - 1\n",
    "        if intron_start < intron_end:\n",
    "            intron_num = i + 1  \n",
    "            introns.append((gene_id, tx, chrom, strand, intron_start, intron_end, intron_num))\n",
    "\n",
    "\n",
    "\n",
    "# Extract sequences from FASTA \n",
    "fasta = pysam.FastaFile(fasta_file)\n",
    "all_refs = set(fasta.references)\n",
    "\n",
    "def normalize_chrom(chrom):\n",
    "    \"\"\"Fix chromosome name mismatches between GTF and FASTA\"\"\"\n",
    "    if chrom in all_refs:\n",
    "        return chrom\n",
    "    if \"chr\" + chrom in all_refs:\n",
    "        return \"chr\" + chrom\n",
    "    if chrom.startswith(\"chr\") and chrom[3:] in all_refs:\n",
    "        return chrom[3:]\n",
    "    return None\n",
    "\n",
    "with open(out_fasta, \"w\") as out_fa, open(out_csv, \"w\") as out_tab:\n",
    "    out_tab.write(\"gene_id,transcript_id,intron_num,chrom,start,end,strand,length\\n\")\n",
    "    for gene_id, tx, chrom, strand, s, e, intron_num in introns:\n",
    "        chrom_name = normalize_chrom(chrom)\n",
    "        if chrom_name is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            seq = fasta.fetch(chrom_name, s-1, e).upper()  \n",
    "        except Exception as ex:\n",
    "            print(f\" Could not fetch {chrom_name}:{s}-{e} for {gene_id}: {ex}\")\n",
    "            continue\n",
    "\n",
    "        if strand == \"-\":  # reverse complement\n",
    "            seq = seq.translate(str.maketrans(\"ACGT\", \"TGCA\"))[::-1]\n",
    "\n",
    "        header = f\">{gene_id}|{tx}|intron{intron_num}|{chrom}:{s}-{e}({strand})\"\n",
    "        out_fa.write(f\"{header}\\n{seq}\\n\")\n",
    "\n",
    "        out_tab.write(f\"{gene_id},{tx},{intron_num},{chrom_name},{s},{e},{strand},{len(seq)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bdef51",
   "metadata": {},
   "source": [
    "### STEP1: Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a910111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length for codon97\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load intron metadata\n",
    "intron_df = pd.read_csv(\"data/introns_9056_metadata.csv\")\n",
    "\n",
    "# Collapse to per-gene total intron length\n",
    "intron_total = (\n",
    "    intron_df.groupby(\"gene_id\")[\"length\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"length\": \"total_intron_length\"})\n",
    ")\n",
    "\n",
    "# Load Codon97 dataset\n",
    "codon97_df = pd.read_csv(\"data/RNA_Proteomics_Filtered.csv\")\n",
    "\n",
    "# Merge on ENSG\n",
    "merged = codon97_df.merge(\n",
    "    intron_total, \n",
    "    left_on=\"ENSG_clean\", \n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Keep only gene name + total intron length\n",
    "result = merged[[\"GeneSymbol\", \"total_intron_length\"]]\n",
    "\n",
    "# Save for downstream analysis\n",
    "result.to_csv(\"data/codon97_intron.csv\", index=False)\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303baeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length for rna level\n",
    "rna_df = pd.read_csv(\"data/RNA_Proteomics_RNAlevel.csv\")\n",
    "\n",
    "rna_df[\"ENSG_clean\"] = rna_df[\"ESGN\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "rna_with_introns = rna_df.merge(\n",
    "    intron_total,\n",
    "    left_on=\"ENSG_clean\",   # make sure this matches your RNA file’s column name\n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "result = rna_with_introns[[\"GeneSymbol\", \"total_intron_length\"]]\n",
    "\n",
    "result.to_csv(\"data/rna_intron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adbd63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length for proteomics\n",
    "prot_df = pd.read_csv(\"data/RNA_Proteomics_Proteinlevel.csv\")\n",
    "\n",
    "prot_df[\"ENSG_clean\"] = prot_df[\"ESGN\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "prot_with_introns = prot_df.merge(\n",
    "    intron_total,\n",
    "    left_on=\"ENSG_clean\",   # make sure this matches your Protein file’s column name\n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "result = prot_with_introns[[\"GeneSymbol\", \"total_intron_length\"]]\n",
    "\n",
    "result.to_csv(\"data/protein_intron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fbe280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length for all_prot\n",
    "\n",
    "all_df = pd.read_csv(\"data/RNA_Proteomics_Merged.csv\")\n",
    "\n",
    "all_df[\"ENSG_clean\"] = all_df[\"Unnamed: 0\"].str.replace(r\"\\.\\d+$\", \"\", regex=True)\n",
    "\n",
    "all_with_introns = all_df.merge(\n",
    "    intron_total,\n",
    "    left_on=\"ENSG_clean\",  \n",
    "    right_on=\"gene_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "all_gene_lengths = (\n",
    "    all_with_introns.groupby(\"GeneSymbol\")[\"total_intron_length\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "all_gene_lengths.to_csv(\"data/all_intron.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f6611",
   "metadata": {},
   "source": [
    "#### bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "codon97_df = pd.read_csv(\"/mnt/work_3/sijin/CAI/codon97_intron.csv\").rename(columns={\"total_intron_length\": \"Length\"})\n",
    "rna_df     = pd.read_csv(\"/mnt/work_3/sijin/CAI/rna_intron.csv\").rename(columns={\"total_intron_length\": \"Length\"})\n",
    "prot_df    = pd.read_csv(\"/mnt/work_3/sijin/CAI/protein_intron.csv\").rename(columns={\"total_intron_length\": \"Length\"})\n",
    "all_df     = pd.read_csv(\"/mnt/work_3/sijin/CAI/all_intron.csv\").rename(columns={\"total_intron_length\": \"Length\"})\n",
    "\n",
    "codon97_df[\"Source\"] = \"Codon97\"\n",
    "rna_df[\"Source\"]     = \"RNAseq_Log2FC>0\"    \n",
    "prot_df[\"Source\"]    = \"Proteomics_Log2FC>0\"\n",
    "all_df[\"Source\"]     = \"All_otherprot_all_Log2FC\"\n",
    "\n",
    "all_data = pd.concat([codon97_df, rna_df, prot_df, all_df], ignore_index=True)\n",
    "all_data[\"Length\"] = pd.to_numeric(all_data[\"Length\"], errors=\"coerce\")\n",
    "all_data = all_data.dropna(subset=[\"Length\"])\n",
    "all_data = all_data[all_data[\"Length\"] > 0] \n",
    "\n",
    "all_data[\"log10_Length\"] = np.log10(all_data[\"Length\"].astype(float))\n",
    "\n",
    "def bootstrap_pvalue_mean(test_vals, all_vals, n_iter=10000, seed=123):\n",
    "    np.random.seed(seed)\n",
    "    test_mean = np.mean(test_vals)\n",
    "    n = len(test_vals)\n",
    "\n",
    "    boot_means = []\n",
    "    for _ in range(n_iter):\n",
    "        sample = np.random.choice(all_vals, size=n, replace=False)\n",
    "        boot_means.append(np.mean(sample))\n",
    "\n",
    "    boot_means = np.array(boot_means)\n",
    "    all_mean = np.mean(all_vals)\n",
    "\n",
    "    # Two-sided p-value around the All mean\n",
    "    pval = np.mean(np.abs(boot_means - all_mean) >= np.abs(test_mean - all_mean))\n",
    "    return test_mean, all_mean, pval\n",
    "\n",
    "all_log = all_data.loc[all_data[\"Source\"] == \"All_otherprot_all_Log2FC\", \"log10_Length\"].values\n",
    "\n",
    "codon97_log = all_data.loc[all_data[\"Source\"] == \"Codon97\", \"log10_Length\"].values\n",
    "rna_log     = all_data.loc[all_data[\"Source\"] == \"RNAseq_Log2FC>0\", \"log10_Length\"].values\n",
    "prot_log    = all_data.loc[all_data[\"Source\"] == \"Proteomics_Log2FC>0\", \"log10_Length\"].values\n",
    "\n",
    "codon97_mean, all_mean1, p_cod_all = bootstrap_pvalue_mean(codon97_log, all_log)\n",
    "rna_mean,     all_mean2, p_rna_all = bootstrap_pvalue_mean(rna_log, all_log)\n",
    "prot_mean,    all_mean3, p_prot_all = bootstrap_pvalue_mean(prot_log, all_log)\n",
    "\n",
    "res_df = pd.DataFrame({\n",
    "    \"Group\": [\"Codon97\", \"RNAseq_Log2FC>0\", \"Proteomics_Log2FC>0\"],\n",
    "    \"Mean_log10_Group\": [codon97_mean, rna_mean, prot_mean],\n",
    "    \"Mean_log10_All\": [all_mean1, all_mean2, all_mean3],\n",
    "    \"p-value (two-sided)\": [p_cod_all, p_rna_all, p_prot_all]\n",
    "})\n",
    "\n",
    "print(\"\\n=== Bootstrap mean test on log10(total intron length): each group vs All_otherprot_all_Log2FC ===\")\n",
    "print(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efe719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "\n",
    "order = [\"Codon97\", \"RNAseq_Log2FC>0\", \"Proteomics_Log2FC>0\", \"All_otherprot_all_Log2FC\"]\n",
    "counts = all_data.groupby(\"Source\").size()\n",
    "\n",
    "custom_palette = {\n",
    "    \"Codon97\": \"#8DD3C7\",\n",
    "    \"RNAseq_Log2FC>0\": \"#c2bed6\",\n",
    "    \"Proteomics_Log2FC>0\": \"#f6f6bc\",\n",
    "    \"All_otherprot_all_Log2FC\": \"#eab375\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.violinplot(\n",
    "    x=\"Source\", y=\"log10_Length\", data=all_data,\n",
    "    inner=None, palette=custom_palette, order=order,\n",
    "    linewidth=1.2, cut=0\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    x=\"Source\", y=\"log10_Length\", data=all_data,\n",
    "    order=order, color=\"black\", alpha=0.2,\n",
    "    jitter=0.25, size=1.5\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    x=\"Source\", y=\"log10_Length\", data=all_data,\n",
    "    order=order, width=0.15, showcaps=True,\n",
    "    boxprops={\"facecolor\": \"grey\", \"edgecolor\": \"black\"},\n",
    "    whiskerprops={\"color\": \"black\"},\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1},\n",
    "    showfliers=False\n",
    ")\n",
    "\n",
    "group_means = all_data.groupby(\"Source\")[\"log10_Length\"].mean()\n",
    "for i, src in enumerate(order):\n",
    "    ax.scatter(i, group_means[src], color=\"white\", edgecolors=\"black\", zorder=3, s=30)\n",
    "\n",
    "y_max = all_data[\"log10_Length\"].max()\n",
    "\n",
    "def add_bracket(x1, x2, y, h, text, fs=10):\n",
    "    plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], c=\"k\", lw=1.2)\n",
    "    plt.text((x1+x2)/2, y+h+0.02, text, ha=\"center\", va=\"bottom\", fontsize=fs, color=\"black\")\n",
    "\n",
    "base_y = y_max + 0.10\n",
    "step_y = 0.35\n",
    "h = 0.10\n",
    "\n",
    "add_bracket(0, 3, base_y + 0*step_y, h, f\"p = {p_cod_all:.4f}*\")\n",
    "add_bracket(1, 3, base_y + 1*step_y, h, f\"p = {p_rna_all:.4f}*\")\n",
    "add_bracket(2, 3, base_y + 2*step_y, h, f\"p = {p_prot_all:.4f}\")\n",
    "\n",
    "ax.set_ylim(all_data[\"log10_Length\"].min() - 0.1, base_y + 2*step_y + h + 0.25)\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=range(len(order)),\n",
    "    labels=[f\"{src}\\n(n={counts.get(src, 0)})\" for src in order]\n",
    ")\n",
    "\n",
    "plt.title(\"Distribution of Total Intron Length (log10-transformed)\", fontsize=14)\n",
    "plt.ylabel(\"log10(Total Intron Length)\", fontsize=12)\n",
    "plt.xlabel(\"\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
